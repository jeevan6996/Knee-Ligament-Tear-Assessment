{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7317ebcd",
   "metadata": {},
   "source": [
    "# Preprocessing of MRNet and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b11e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266fdf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrnet_dataset_dir = 'Data/MRNet-v1.0'\n",
    "mrnet_train_path = os.path.join(mrnet_dataset_dir, 'train')\n",
    "mrnet_valid_path = os.path.join(mrnet_dataset_dir, 'valid')\n",
    "mrnet_planes = ['axial', 'coronal', 'sagittal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c958f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For running code on Windows\n",
    "if platform.system() == \"Windows\":\n",
    "    mrnet_dataset_dir = mrnet_dataset_dir.replace('/', '\\\\')\n",
    "    mrnet_train_path = mrnet_train_path.replace('/', '\\\\')\n",
    "    mrnet_valid_path = mrnet_valid_path.replace('/', '\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb8c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrnet_datasets = {'train': mrnet_train_path, 'valid': mrnet_valid_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daccb5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrnet_labels = ['abnormal', 'acl', 'meniscus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6366de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN DATASET\n",
    "for label in mrnet_labels:\n",
    "    if platform.system() == \"Windows\":\n",
    "        if label == 'abnormal':\n",
    "            train_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Abnormal'],\n",
    "                                            dtype={'Case': str, 'Abnormal': np.int64})\n",
    "        elif label == 'acl':\n",
    "            train_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-{label}.csv\",\n",
    "                                       header=None,\n",
    "                                       names=['Case', 'ACL'],\n",
    "                                       dtype={'Case': str, 'ACL': np.int64})\n",
    "        if label == 'meniscus':\n",
    "            train_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Meniscus'],\n",
    "                                            dtype={'Case': str, 'Meniscus': np.int64})\n",
    "    else:\n",
    "        if label == 'abnormal':\n",
    "            train_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Abnormal'],\n",
    "                                            dtype={'Case': str, 'Abnormal': np.int64})\n",
    "        elif label == 'acl':\n",
    "            train_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-{label}.csv\",\n",
    "                                       header=None,\n",
    "                                       names=['Case', 'ACL'],\n",
    "                                       dtype={'Case': str, 'ACL': np.int64})\n",
    "        if label == 'meniscus':\n",
    "            train_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Meniscus'],\n",
    "                                            dtype={'Case': str, 'Meniscus': np.int64})\n",
    "\n",
    "train_df = pd.merge(train_abnormal_df, train_acl_df, on='Case').merge(train_meniscus_df, on='Case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4528e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALID DATASET\n",
    "for label in mrnet_labels:\n",
    "    if platform.system() == \"Windows\":\n",
    "        if label == 'abnormal':\n",
    "            valid_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Abnormal'],\n",
    "                                            dtype={'Case': str, 'Abnormal': np.int64})\n",
    "        elif label == 'acl':\n",
    "            valid_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-{label}.csv\",\n",
    "                                       header=None,\n",
    "                                       names=['Case', 'ACL'],\n",
    "                                       dtype={'Case': str, 'ACL': np.int64})\n",
    "        if label == 'meniscus':\n",
    "            valid_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Meniscus'],\n",
    "                                            dtype={'Case': str, 'Meniscus': np.int64})\n",
    "    else:\n",
    "        if label == 'abnormal':\n",
    "            valid_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Abnormal'],\n",
    "                                            dtype={'Case': str, 'Abnormal': np.int64})\n",
    "        elif label == 'acl':\n",
    "            valid_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-{label}.csv\",\n",
    "                                       header=None,\n",
    "                                       names=['Case', 'ACL'],\n",
    "                                       dtype={'Case': str, 'ACL': np.int64})\n",
    "        if label == 'meniscus':\n",
    "            valid_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Meniscus'],\n",
    "                                            dtype={'Case': str, 'Meniscus': np.int64})\n",
    "\n",
    "valid_df = pd.merge(valid_abnormal_df, valid_acl_df, on='Case').merge(valid_meniscus_df, on='Case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b87c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mri_vols(cases, overwrite=False):\n",
    "    \"\"\"\n",
    "    This function preprocesses all the MRI volumes in MRNet\n",
    "    and stores them under 'Preprocessed_Data' directory.\n",
    "\n",
    "    Args:\n",
    "        cases (list): List of files in MRNet dataset\n",
    "        overwrite (bool, optional): Option to overwrite already preprocessed MRI\n",
    "    \"\"\"\n",
    "    cases.sort()\n",
    "    for case in cases:\n",
    "        mri_vol = np.load(case)\n",
    "        mri_vol = mri_vol.astype(np.float64)  # Change the dtype to float64\n",
    "\n",
    "        case_path = os.path.normpath(case).split(os.sep)\n",
    "        case_path[0] = 'Preprocessed_Data'\n",
    "        preprocessed_case_path = os.path.join(*case_path)\n",
    "\n",
    "        if overwrite or not os.path.exists(preprocessed_case_path):\n",
    "            preprocessed_mri_vol = utils.preprocess_mri(mri_vol)\n",
    "            os.makedirs(os.path.join(*case_path[:-1]), exist_ok=True)\n",
    "            np.save(preprocessed_case_path, preprocessed_mri_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e92f3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_mri_vols(dataset, labels, aug_flip_prob=0.95, overwrite=False):\n",
    "    \"\"\"\n",
    "    This function augments MRI volumes in MRNet dataset to create more samples\n",
    "    for labels that have lower number of cases.\n",
    "\n",
    "    Args:\n",
    "        dataset (str): Path to either train or valid MRNet dataset\n",
    "        labels (Pandas dataframe): Labels dataframe for the exams\n",
    "        aug_flip_prob (float, optional): Augmentation flip probability\n",
    "        overwrite (bool, optional): Option to overwrite already preprocessed MRI\n",
    "    \"\"\"\n",
    "    aug_labels_list = []\n",
    "    plane = 'sagittal'\n",
    "    if platform.system() == \"Windows\":\n",
    "        cases = glob(f\"{dataset}\\\\{plane}\\\\*.npy\")\n",
    "    else:\n",
    "        cases = glob(f\"{dataset}/{plane}/*.npy\")\n",
    "    cases.sort()\n",
    "    for case in cases:\n",
    "        # We will create a new path file for augmented images by adding '_aug' in file names\n",
    "        # and we store them under the folder <plane>/aug\n",
    "\n",
    "        case_path = os.path.normpath(case).split(os.sep)\n",
    "        file_name = case_path[-1]\n",
    "\n",
    "        orig_sagittal = os.path.join(*case_path)\n",
    "\n",
    "        case_path[0] = 'Preprocessed_Data'\n",
    "        case_path.insert(-1, 'aug')\n",
    "\n",
    "        # SAGITTAL\n",
    "        sa_temp = file_name\n",
    "        dot_index = sa_temp.index('.')\n",
    "\n",
    "        # Do this only once as the label of augmented MRIs will be the same for all three planes and tasks\n",
    "        temp_aug_labels = labels.loc[labels['Case'] == sa_temp[:dot_index]][['Abnormal', 'ACL', 'Meniscus']].values.tolist()[0]\n",
    "\n",
    "        # If acl_diagnosis is 1, only 5% chance of augmentation as majority samples are without tear\n",
    "        # Increase probability of augmentation in case of ACL tears\n",
    "        if np.random.rand() >= aug_flip_prob or temp_aug_labels[1] == 1:\n",
    "\n",
    "            case_path[-1] = f\"{sa_temp[:dot_index]}-aug-0{sa_temp[dot_index:]}\"\n",
    "            aug_sagittal = os.path.join(*case_path)\n",
    "\n",
    "            if temp_aug_labels[1] == 0:\n",
    "                if overwrite or not os.path.exists(aug_sagittal):\n",
    "                    mri_vol = np.load(orig_sagittal)\n",
    "                    mri_vol = mri_vol.astype(np.float64)  # Change the dtype to float64\n",
    "\n",
    "                    aug_mri_vol = utils.random_horizontal_flip(mri_vol)\n",
    "                    aug_mri_vol = utils.random_rotation(aug_mri_vol)\n",
    "\n",
    "                    preprocessed_aug_mri_vol = utils.preprocess_mri(aug_mri_vol)\n",
    "                    os.makedirs(os.path.join(*case_path[:-1]), exist_ok=True)\n",
    "                    np.save(aug_sagittal, preprocessed_aug_mri_vol)\n",
    "                    aug_labels_list.append([f\"{sa_temp[:dot_index]}-aug-0\"] + temp_aug_labels)\n",
    "\n",
    "            elif temp_aug_labels[1] == 1:\n",
    "                for aug_ind in range(3):  # We will augment sample three times\n",
    "                    if aug_ind >= 1:\n",
    "                        case_path[-1] = f\"{sa_temp[:dot_index]}-aug-{aug_ind}{sa_temp[dot_index:]}\"\n",
    "                        aug_sagittal = os.path.join(*case_path)\n",
    "\n",
    "                    if overwrite or not os.path.exists(aug_sagittal):\n",
    "                        mri_vol = np.load(orig_sagittal)\n",
    "                        mri_vol = mri_vol.astype(np.float64)  # Change the dtype to float64\n",
    "\n",
    "                        if aug_ind == 0:\n",
    "                            aug_mri_vol = utils.random_horizontal_flip(mri_vol)\n",
    "                        elif aug_ind == 1:\n",
    "                            aug_mri_vol = utils.random_rotation(mri_vol)\n",
    "                        elif aug_ind == 2:\n",
    "                            aug_mri_vol = utils.random_horizontal_flip(mri_vol)\n",
    "                            aug_mri_vol = utils.random_rotation(aug_mri_vol)\n",
    "                        preprocessed_aug_mri_vol = utils.preprocess_mri(aug_mri_vol)\n",
    "                        os.makedirs(os.path.join(*case_path[:-1]), exist_ok=True)\n",
    "                        np.save(aug_sagittal, preprocessed_aug_mri_vol)\n",
    "                        aug_labels_list.append([f\"{sa_temp[:dot_index]}-aug-{aug_ind}\"] + temp_aug_labels)\n",
    "\n",
    "    aug_train_df = pd.DataFrame(aug_labels_list, columns=labels.columns)\n",
    "    # print(aug_train_df)\n",
    "    csv_file_path = os.path.normpath(dataset).split(os.sep)\n",
    "    if csv_file_path[-1] == 'train':\n",
    "        if platform.system() == \"Windows\":\n",
    "            aug_train_df.to_csv(os.path.join(*csv_file_path[:-1]) + \"\\\\train-aug.csv\")\n",
    "        else:\n",
    "            aug_train_df.to_csv(os.path.join(*csv_file_path[:-1]) + \"/train-aug.csv\")\n",
    "    elif csv_file_path[-1] == 'valid':\n",
    "        if platform.system() == \"Windows\":\n",
    "            aug_train_df.to_csv(os.path.join(*csv_file_path[:-1]) + \"\\\\valid-aug.csv\")\n",
    "        else:\n",
    "            aug_train_df.to_csv(os.path.join(*csv_file_path[:-1]) + \"/valid-aug.csv\")\n",
    "    print(f\"For {dataset.upper()} datset we have {len(aug_labels_list)} augmented samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6655a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mri_vols_for_plane(dataset, plane):\n",
    "    \"\"\"\n",
    "    This function calls preprocessing on given dataset of MRNet\n",
    "    and plane.\n",
    "\n",
    "    Args:\n",
    "        dataset (str): Path to either train or valid MRNet dataset\n",
    "        plane (str): MRNet dataset plane axial, coronal or sagittal\n",
    "    \"\"\"\n",
    "    if platform.system() == \"Windows\":\n",
    "        cases = glob(f\"{dataset}\\\\{plane}\\\\*.npy\")\n",
    "    else:\n",
    "        cases = glob(f\"{dataset}/{plane}/*.npy\")\n",
    "    preprocess_mri_vols(cases)\n",
    "    print(f\"For {dataset.upper()} {plane} plane we have {len(cases)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b7b3aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For DATA\\MRNET-V1.0\\TRAIN sagittal plane we have 1130 samples.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess only sagittal plane\n",
    "preprocess_mri_vols_for_plane(mrnet_datasets['train'], 'sagittal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87eb4445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For DATA\\MRNET-V1.0\\VALID sagittal plane we have 120 samples.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess only sagittal plane\n",
    "preprocess_mri_vols_for_plane(mrnet_datasets['valid'], 'sagittal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d0731a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For DATA\\MRNET-V1.0\\TRAIN datset we have 664 augmented samples.\n"
     ]
    }
   ],
   "source": [
    "augment_mri_vols(mrnet_datasets['train'], train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f055f39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For DATA\\MRNET-V1.0\\VALID datset we have 166 augmented samples.\n"
     ]
    }
   ],
   "source": [
    "augment_mri_vols(mrnet_datasets['valid'], valid_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
